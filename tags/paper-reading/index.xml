<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>Paper Reading - 标签 - Adbean&#39;s Blog</title>
        <link>https://ad-bean.github.io/tags/paper-reading/</link>
        <description>Paper Reading - 标签 - Adbean&#39;s Blog</description>
        <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>adbeanx@outlook.com (Adbean)</managingEditor>
            <webMaster>adbeanx@outlook.com (Adbean)</webMaster><lastBuildDate>Wed, 26 Feb 2025 22:39:12 -0500</lastBuildDate><atom:link href="https://ad-bean.github.io/tags/paper-reading/" rel="self" type="application/rss+xml" /><item>
    <title>Paper Reading: Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM</title>
    <link>https://ad-bean.github.io/posts/paper-megatron-lm-v2/</link>
    <pubDate>Wed, 26 Feb 2025 22:39:12 -0500</pubDate>
    <author>Adbean</author>
    <guid>https://ad-bean.github.io/posts/paper-megatron-lm-v2/</guid>
    <description><![CDATA[Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM 姑且算作 Megatron LM v2，因为是晚一年发表的，粗略过一下，因为都是同样的 motivation 和 background 等等 知乎一篇不错的总结 作者 Jared 的视频介绍 其中和 ZeRO 的对]]></description>
</item>
<item>
    <title>Paper Reading: Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism</title>
    <link>https://ad-bean.github.io/posts/paper-megatron-lm/</link>
    <pubDate>Wed, 26 Feb 2025 13:19:30 -0500</pubDate>
    <author>Adbean</author>
    <guid>https://ad-bean.github.io/posts/paper-megatron-lm/</guid>
    <description><![CDATA[Megatron-LM Nvidia 开源的 Megatron-LM 大模型训练框架 结合 Model Parallelism 和 Pipeline Parallelism 实现了 Tensor Model Parallelism 基于 Transformer 和 Attention 进行切分，同样是经典的一篇分布式语言模型训练的文章 论文比较短，细节很少，需要结]]></description>
</item>
<item>
    <title>Paper Reading: PipeDream: Generalized Pipeline Parallelism for DNN Training [SOSP2019]</title>
    <link>https://ad-bean.github.io/posts/paper-pipedream/</link>
    <pubDate>Mon, 24 Feb 2025 10:49:51 -0500</pubDate>
    <author>Adbean</author>
    <guid>https://ad-bean.github.io/posts/paper-pipedream/</guid>
    <description><![CDATA[PipeDream: Generalized Pipeline Parallelism for DNN Training 第一次看 ML/DL (distributed) training 框架相关的论文，有很多地方不理解。 对 Evaluation 与数学证明更是浅尝辄止，许多指标和算法难以理解，关于大模型、分布式训练等等]]></description>
</item>
<item>
    <title>Paper Reading: From Cloud Computing to Sky Computing</title>
    <link>https://ad-bean.github.io/posts/paper-skycomputing/</link>
    <pubDate>Wed, 04 Dec 2024 11:25:04 -0500</pubDate>
    <author>Adbean</author>
    <guid>https://ad-bean.github.io/posts/paper-skycomputing/</guid>
    <description><![CDATA[From Cloud Computing to Sky Computing 21 年 UCB 提出了 Sky Computing 的概念，后续也有一篇 35 页的 The Sky Above The Clouds 相比起传统的云服务，sky computing 更像一个大一统的中间层，比如可以调用不同的云服务]]></description>
</item>
<item>
    <title>Paper Reading: ServiceRouter: Hyperscale and Minimal Cost Service Mesh at Meta</title>
    <link>https://ad-bean.github.io/posts/paper-servicerouter/</link>
    <pubDate>Mon, 02 Dec 2024 09:37:05 -0500</pubDate>
    <author>Adbean</author>
    <guid>https://ad-bean.github.io/posts/paper-servicerouter/</guid>
    <description><![CDATA[ServiceRouter: Hyperscale and Minimal Cost Service Mesh at Meta Meta 的全球服务网格 ServiceRouter（SR） 服务网格（Service Mesh）是一种用于处理微服务架构中服务之间通信]]></description>
</item>
<item>
    <title>Paper Reading: From Laptop to Lambda: Outsourcing Everyday Jobs to Thousands of Transient Functional Containers</title>
    <link>https://ad-bean.github.io/posts/paper-gg/</link>
    <pubDate>Wed, 20 Nov 2024 01:09:31 -0500</pubDate>
    <author>Adbean</author>
    <guid>https://ad-bean.github.io/posts/paper-gg/</guid>
    <description><![CDATA[From Laptop to Lambda: Outsourcing Everyday Jobs to Thousands of Transient Functional Containers 同样是 standford DBOS 组关于 serverless 的论文，作者还有一篇 R2E2 很厉害，用 serverless 做 ray tracing 实现很高的加速，但 cost 估计控制不住 Abstract gg framework users might push a button that spawns 10,000 parallel]]></description>
</item>
<item>
    <title>Paper Reading: Apiary: A DBMS-Integrated Transactional Function-as-a-Service Framework</title>
    <link>https://ad-bean.github.io/posts/paper-apiary/</link>
    <pubDate>Sat, 16 Nov 2024 16:08:33 -0500</pubDate>
    <author>Adbean</author>
    <guid>https://ad-bean.github.io/posts/paper-apiary/</guid>
    <description><![CDATA[Apiary: A DBMS-Backed Transactional Function-as-a-Service Framework 来自 DBOS 的一个很有意思的项目，DBOS 这个项目去年关注过，txn + serverless 很有趣的思路 传统 FaaS 客户端调用函数去连接 DB 查询 DBOS 直接 DB as OS，提]]></description>
</item>
<item>
    <title>Paper Reading: Delta Lake High-Performance ACID Table Storage over Cloud Object Stores</title>
    <link>https://ad-bean.github.io/posts/paper-delta-lake/</link>
    <pubDate>Mon, 11 Nov 2024 11:24:58 -0500</pubDate>
    <author>Adbean</author>
    <guid>https://ad-bean.github.io/posts/paper-delta-lake/</guid>
    <description><![CDATA[Delta Lake: High-Performance ACID Table Storage over Cloud Object Stores https://github.com/delta-io/delta data lake? delta lake? data warehouse? databricks 的论文 DeltaLake 类似的产品有 Hudi, Iceberg, Apache Paimon 其他论文笔记 https://www.cnblogs.com/Aitozi/p/17552466.html 大数据技术换代也太快了，但底层原理我还是一问三不知，还得练 Towards Multi-Table]]></description>
</item>
<item>
    <title>Paper Reading: Ownership: A Distributed Futures System for Fine-Grained Tasks</title>
    <link>https://ad-bean.github.io/posts/paper-ownership/</link>
    <pubDate>Sun, 10 Nov 2024 16:27:22 -0500</pubDate>
    <author>Adbean</author>
    <guid>https://ad-bean.github.io/posts/paper-ownership/</guid>
    <description><![CDATA[Ownership: A Distributed Futures System for Fine-Grained Tasks 分布式系统中的一些任务调度的论文，本来是要看 Ray 的，同样都是 UCB 的研究（分布式机器学习框架） Ownership 我一开始还以为是 Rust 里的所有权概念，]]></description>
</item>
<item>
    <title>Paper Reading: AIFM: High-Performance, Application-Integrated Far Memory (OSDI 20)</title>
    <link>https://ad-bean.github.io/posts/paper-aifm/</link>
    <pubDate>Wed, 06 Nov 2024 11:28:34 -0500</pubDate>
    <author>Adbean</author>
    <guid>https://ad-bean.github.io/posts/paper-aifm/</guid>
    <description><![CDATA[AIFM: High-Performance, Application-Integrated Far Memory Disaggregated Memory 领域的论文，之前稍微看了一点，挺有意思的从应用层面用远端内存 Zhenyuan Ruan, Malte Schwarzkopf 和 Adam Belay，zhenyuan 在 osdi 20 中了不少论文，很多都]]></description>
</item>
</channel>
</rss>
